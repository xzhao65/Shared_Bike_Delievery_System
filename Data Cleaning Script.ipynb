{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import min, max\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import *\n",
    "import datetime\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+------+------------+---------------+--------------------+-------------+--------------------+----------+------+---------+\n",
      "| trip_id|        start_time|          end_time|bikeid|tripduration|from_station_id|   from_station_name|to_station_id|     to_station_name|  usertype|gender|birthyear|\n",
      "+--------+------------------+------------------+------+------------+---------------+--------------------+-------------+--------------------+----------+------+---------+\n",
      "|13518905|3/31/2017 23:59:07| 4/1/2017 00:13:24|  5292|         857|             66|Clinton St & Lake St|          171|May St & Cullerto...|Subscriber|  Male|     1989|\n",
      "|13518904|3/31/2017 23:56:25| 4/1/2017 00:00:21|  4408|         236|            199|Wabash Ave & Gran...|           26|McClurg Ct & Illi...|Subscriber|  Male|     1990|\n",
      "|13518903|3/31/2017 23:55:33| 4/1/2017 00:01:21|   696|         348|            520|Greenview Ave & J...|          432| Clark St & Lunt Ave|Subscriber|Female|     1979|\n",
      "|13518902|3/31/2017 23:54:46|3/31/2017 23:59:34|  4915|         288|            110|Dearborn St & Eri...|          142|McClurg Ct & Erie St|Subscriber|  Male|     1985|\n",
      "|13518901|3/31/2017 23:53:33| 4/1/2017 00:00:28|  4247|         415|            327|Sheffield Ave & W...|          331|Halsted St & Blac...|Subscriber|Female|     1989|\n",
      "|13518900|3/31/2017 23:51:17|3/31/2017 23:55:19|  3536|         242|            143|Sedgwick St & Web...|          289|Wells St & Concor...|Subscriber|  Male|     1988|\n",
      "|13518899|3/31/2017 23:51:16|3/31/2017 23:57:17|  5111|         361|             81|  Daley Center Plaza|           41|Federal St & Polk St|Subscriber|  Male|     1987|\n",
      "|13518898|3/31/2017 23:50:26|3/31/2017 23:56:20|  1579|         354|             56|Desplaines St & K...|           77|Clinton St & Madi...|Subscriber|  Male|     1981|\n",
      "|13518897|3/31/2017 23:50:25|3/31/2017 23:55:24|  3914|         299|            210|Ashland Ave & Div...|           69|Damen Ave & Pierc...|Subscriber|  Male|     1992|\n",
      "|13518896|3/31/2017 23:49:58| 4/1/2017 00:09:31|  5455|        1173|            117|Wilton Ave & Belm...|           29|Noble St & Milwau...|Subscriber|  Male|     1989|\n",
      "|13518895|3/31/2017 23:49:51| 4/1/2017 00:09:31|  4282|        1180|            117|Wilton Ave & Belm...|           29|Noble St & Milwau...|Subscriber|  Male|     1989|\n",
      "|13518894|3/31/2017 23:49:34|3/31/2017 23:57:58|  4768|         504|            227|Southport Ave & W...|          303|Broadway & Cornel...|Subscriber|  Male|     1988|\n",
      "|13518893|3/31/2017 23:49:12|3/31/2017 23:53:07|  2505|         235|            199|Wabash Ave & Gran...|           26|McClurg Ct & Illi...|Subscriber|Female|     1990|\n",
      "|13518892|3/31/2017 23:48:35|3/31/2017 23:52:51|   142|         256|             59|Wabash Ave & Roos...|            2| Buckingham Fountain|Subscriber|  Male|     1984|\n",
      "|13518891|3/31/2017 23:45:51|3/31/2017 23:55:41|  1407|         590|             67|Sheffield Ave & F...|          250|Ashland Ave & Wel...|Subscriber|  Male|     1982|\n",
      "|13518890|3/31/2017 23:45:39|3/31/2017 23:48:09|  3914|         150|            333|Ashland Ave & Bla...|          210|Ashland Ave & Div...|Subscriber|  Male|     1992|\n",
      "|13518889|3/31/2017 23:45:21|3/31/2017 23:52:48|  4631|         447|             77|Clinton St & Madi...|          175|  Wells St & Polk St|Subscriber|Female|     1979|\n",
      "|13518888|3/31/2017 23:45:00|3/31/2017 23:50:29|  2790|         329|             90|     Millennium Park|            2| Buckingham Fountain|Subscriber|  Male|     1980|\n",
      "|13518887|3/31/2017 23:44:16|3/31/2017 23:48:53|  5739|         277|             38|  Clark St & Lake St|           24|Fairbanks Ct & Gr...|Subscriber|  Male|     1990|\n",
      "|13518886|3/31/2017 23:43:24|3/31/2017 23:58:07|   790|         883|             91|Clinton St & Wash...|          182|   Wells St & Elm St|Subscriber|  Male|     1970|\n",
      "+--------+------------------+------------------+------+------------+---------------+--------------------+-------------+--------------------+----------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Following shows the original data table we have.\n",
    "trips=spark.read.csv(\"/zhaoxiangyu/DIvvy/Divvy_Trips_2017_Q1.csv\",header=True,inferSchema=True)\n",
    "trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(file):\n",
    "    #Key step of data transformation is to count the number of entries for each staion grouped by same time period \n",
    "    trips=spark.read.csv(\"~/DIvvy/\"+file+\".csv\",header=True,inferSchema=True)\n",
    "    trips.createOrReplaceTempView(\"trips\")\n",
    "    temp=spark.sql(\"select trip_id,start_time,end_time,bikeid,tripduration,from_station_name,to_station_name from trips\")\n",
    "    temp.createOrReplaceTempView(\"temp\")\n",
    "    temp2=temp.rdd.map(lambda row : [row.start_time.split(\" \")[0],row.start_time.split(\" \")[1],row.end_time.split(\" \")[0],row.end_time.split(\" \")[1],row.trip_id])\n",
    "    temp3=temp2.map(lambda row : [row[0].split(\"/\")[0],row[0].split(\"/\")[1],row[0].split(\"/\")[2],row[1].split(\":\")[0],row[1].split(\":\")[1],row[2].split(\"/\")[0],row[2].split(\"/\")[1],row[2].split(\"/\")[2],row[3].split(\":\")[0],row[3].split(\":\")[1],datetime.date(int(row[0].split(\"/\")[2]), int(row[0].split(\"/\")[0]), int(row[0].split(\"/\")[1])).isocalendar()[1],datetime.date(int(row[0].split(\"/\")[2]), int(row[0].split(\"/\")[0]), int(row[0].split(\"/\")[1])).isocalendar()[2],row[4]])\n",
    "    \n",
    "    #This is step for assigning data type for each column.\n",
    "    time = sqlContext.createDataFrame(temp3).select(col(\"_1\").alias(\"start_month\").cast(IntegerType()), \\\n",
    "            col(\"_2\").alias(\"start_day\").cast(IntegerType()), \\\n",
    "            col(\"_3\").alias(\"start_year\").cast(IntegerType()), \\\n",
    "            col(\"_4\").alias(\"start_hour\").cast(IntegerType()), \\\n",
    "            col(\"_5\").alias(\"start_min\").cast(IntegerType()), \\\n",
    "            col(\"_6\").alias(\"end_month\").cast(IntegerType()), \\\n",
    "            col(\"_7\").alias(\"end_day\").cast(IntegerType()), \\\n",
    "            col(\"_8\").alias(\"end_year\").cast(IntegerType()), \\\n",
    "            col(\"_9\").alias(\"end_hour\").cast(IntegerType()), \\\n",
    "            col(\"_10\").alias(\"end_min\").cast(IntegerType()), \\\n",
    "            col(\"_11\").alias(\"week\").cast(IntegerType()), \\\n",
    "            col(\"_12\").alias(\"day_of_week\").cast(IntegerType()), \\\n",
    "            col(\"_13\").alias(\"trip_id\").cast(IntegerType()), \\\n",
    "           )\n",
    "    \n",
    "    temp4=spark.sql(\"select trip_id,bikeid,tripduration,from_station_name,to_station_name from trips\")\n",
    "    data=time.join(temp4,\"trip_id\")\n",
    "    data.createOrReplaceTempView(\"data\")\n",
    "    data_start_count=data.groupBy(['start_day','start_year','start_hour','week','day_of_week','from_station_name']).count().withColumnRenamed('count','start_count').withColumnRenamed(\"from_station_name\", \"station_name\")\n",
    "    data_end_count=data.groupBy(['start_day','start_year','start_hour','week','day_of_week','to_station_name']).count().withColumnRenamed('count','end_count').withColumnRenamed(\"to_station_name\", \"station_name\")\n",
    "    \n",
    "    #Join outflow table and inflow table together, we could calculate the number of total flow for any hour.\n",
    "    training_data=data_start_count.join(data_end_count,['start_day','start_year','start_hour','week','day_of_week','station_name'])\n",
    "    training_data.write.option(\"header\", \"true\").csv(\"~/DIvvy/training_sets/\"+file+\"_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the transformation function for each quarter of data from one year \n",
    "run(\"Divvy_Trips_2017_Q1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"Divvy_Trips_2017_Q1\"\n",
    "trips=spark.read.csv(\"/zhaoxiangyu/DIvvy/training_sets/\"+file+\"_training.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+----+-----------+--------------------+-----------+---------+\n",
      "|start_day|start_year|start_hour|week|day_of_week|        station_name|start_count|end_count|\n",
      "+---------+----------+----------+----+-----------+--------------------+-----------+---------+\n",
      "|        1|      2017|         7|   5|          3|Clinton St & Wash...|         35|       10|\n",
      "|        1|      2017|         9|   9|          3|Orleans St & Merc...|          2|        3|\n",
      "|        1|      2017|        10|  52|          7|Clifton Ave & Arm...|          1|        2|\n",
      "|        1|      2017|        11|   9|          3| Canal St & Adams St|          2|        1|\n",
      "|        1|      2017|        14|   9|          3|Green St & Randol...|          1|        1|\n",
      "|        1|      2017|        16|   5|          3| Canal St & Adams St|          4|       33|\n",
      "|        1|      2017|        17|   9|          3|  Clark St & Lake St|          6|        1|\n",
      "|        1|      2017|        17|   9|          3|Clinton St & Lake St|          8|        8|\n",
      "|        1|      2017|        19|   5|          3|Canal St & Madiso...|          1|        5|\n",
      "|        1|      2017|        19|   9|          3|Clark St & Leland...|          1|        1|\n",
      "|        2|      2017|         7|   5|          4|Dearborn St & Eri...|          2|        4|\n",
      "|        2|      2017|         8|   5|          4|Clark St & Lincol...|          3|        1|\n",
      "|        2|      2017|         8|   9|          4|Wilton Ave & Dive...|          1|        2|\n",
      "|        2|      2017|        12|   9|          4|Loomis St & Taylo...|          1|        1|\n",
      "|        2|      2017|        13|   9|          4|Broadway & Barry Ave|          2|        1|\n",
      "|        2|      2017|        15|   5|          4|   900 W Harrison St|          1|        1|\n",
      "|        2|      2017|        15|   5|          4|California Ave & ...|          1|        1|\n",
      "|        2|      2017|        16|   5|          4|Sheffield Ave & W...|          1|        1|\n",
      "|        2|      2017|        16|   9|          4|Wabash Ave & Gran...|          5|        2|\n",
      "|        2|      2017|        16|   9|          4|Wolcott Ave & Pol...|          6|        1|\n",
      "+---------+----------+----------+----+-----------+--------------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a demo for generated data.\n",
    "trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"Divvy_Trips_2017_Q3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"Divvy_Trips_2017_Q4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"Divvy_Trips_2017_Q2\"\n",
    "trips=spark.read.csv(\"/zhaoxiangyu/DIvvy/training_sets/\"+file+\"_training.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
